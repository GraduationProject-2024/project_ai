import openai
import configparser

from text_119_utils.detect_language import detect_language

# API í‚¤ ì„¤ì •
config = configparser.ConfigParser()
config.read('C:/Users/user/Desktop/project_ai/keys.config')
openai.api_key = config['API_KEYS']['chatgpt_api_key']



def generate_title_and_type(content):
    """
    ì‹ ê³  ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ ì œëª©(í•œê¸€ & ì˜ì–´)ê³¼ emergency_typeì„ ìƒì„±
    """
    prompt = f"""
    Analyze the following emergency report and generate:
    1. A concise and descriptive title in Korean.
    2. The same title translated into English.
    3. The appropriate emergency type from the following categories: Fire, Salvage, Emergency, Traffic Accident, Disaster. 
       If the content does not fit any of these categories, return 'Etc'.

    Return the results in JSON format:
    {{
        "title_ko": "Korean title",
        "title_en": "English title",
        "emergency_type": "Selected category"
    }}

    ---
    {content}
    ---
    """

    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "system", "content": prompt}],
            max_tokens=150
        )
        result = response.choices[0].message.content.strip()

        # âœ… JSON ë³€í™˜ (ì˜ˆì™¸ ì²˜ë¦¬)
        import json
        try:
            data = json.loads(result)
            title_ko = data.get("title_ko", "ê¸´ê¸‰ ì‹ ê³ ")
            title_en = data.get("title_en", "Emergency Report")
            emergency_type = data.get("emergency_type", "Etc")  # ê¸°ë³¸ê°’ "Etc"
        except json.JSONDecodeError:
            print("âŒ JSON ë³€í™˜ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ë°˜í™˜")
            title_ko = "ê¸´ê¸‰ ì‹ ê³ "
            title_en = "Emergency Report"
            emergency_type = "Etc"

        return title_ko, title_en, emergency_type

    except Exception as e:
        print(f"âŒ ì œëª© ë° ìœ í˜• ìƒì„± ì‹¤íŒ¨: {e}")
        return "ê¸´ê¸‰ ì‹ ê³ ", "Emergency Report", "Etc"

import json
def summarize_content(content):
    # """
    # ì‹ ê³  ë‚´ìš©ì„ 400ì ì´ë‚´ë¡œ ìš”ì•½í•˜ê³ , ì›ë˜ ì‚¬ìš©ëœ ì–¸ì–´ ì •ë³´ë¥¼ ì¶”ê°€
    # """
    # detected_language = detect_language(content)  # ì–¸ì–´ ê°ì§€
    # if detected_language == "í•œêµ­ì–´":
    #     if len(content) <= 400:
    #         prompt = f"""
    #         Refine the following text in {detected_language} to remove any vulgar, insulting, or offensive language,
    #         while keeping the original meaning. If the text is already appropriate, return it as it is.
            
    #         ---
    #         {content}
    #         ---
    #         """
    #         max_tokens = 400
    #     else:
    #         prompt = f"""
    #         Summarize the following content in natural Korean within 400 characters while refining any vulgar, insulting,
    #         or offensive language. Ensure that the meaning remains intact.
        
    #         ---
    #         {content}
    #         ---
    #         """
    #         max_tokens = 400
    # elif detected_language == "ì˜ì–´":
    #     if len(content) <= 800:
    #         prompt = f"""
    #         Refine the following text in {detected_language} to remove any vulgar, insulting, or offensive language,
    #         while keeping the original meaning. If the text is already appropriate, return it as it is.
            
    #         ---
    #         {content}
    #         ---
    #         """
    #         max_tokens = 800
    #     else:
    #         prompt = f"""
    #         Summarize the following content in natural English within 800 characters while refining any vulgar, insulting,
    #         or offensive language. Ensure that the meaning remains intact.
        
    #         ---
    #         {content}
    #         ---
    #         """
    #         max_tokens = 800
    # # else:
    # #     # ë‹¤ë¥¸ ì–¸ì–´ë¼ë©´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ê³  378ì ì´ë‚´ë¡œ ìš”ì•½
    # #     prompt = f"""
    # #     Translate the following content into natural Korean and summarize it within 378 characters while refining
    # #     any vulgar, insulting, or offensive language. Ensure that the meaning remains intact.
        
    # #     ---
    # #     {content}
    # #     ---
    # #     """
    # #     max_tokens = 378
    # else:
    #     # ë‹¤ë¥¸ ì–¸ì–´ë¼ë©´ ì˜ì–´ë¡œ ë²ˆì—­í•˜ê³  756ì ì´ë‚´ë¡œ ìš”ì•½
    #     prompt = f"""
    #     Translate the following content into natural English and summarize it within 756 characters while refining
    #     any vulgar, insulting, or offensive language. Ensure that the meaning remains intact.
        
    #     ---
    #     {content}
    #     ---
    #     """
    #     max_tokens = 756
    """
    ì‹ ê³  ë‚´ìš©ì„ ì˜ì–´ì™€ í•œêµ­ì–´ë¡œ ë²ˆì—­ & ìš”ì•½ (ì´ 800 bytes ì´ë‚´)
    - ëª¨ë“  ì–¸ì–´ë¥¼ ê°ì§€í•˜ì—¬ ì˜ì–´ì™€ í•œêµ­ì–´ë¡œ ë³€í™˜
    - ìš•ì„¤ ë° ë¶ˆì¾Œí•œ í‘œí˜„ì„ í•„í„°ë§í•˜ì—¬ ì •ì œ
    """
    detected_language = detect_language(content)  # ì–¸ì–´ ê°ì§€

    prompt = f"""
    Analyze the following report and generate a refined summary in both Korean and English.
    - Ensure that any vulgar, insulting, or offensive language is removed while preserving the original meaning.
    - Translate the content into natural Korean and English.
    - The combined length of both summaries should not exceed 800 bytes.
    - Adjust the length of each language appropriately to fit within the limit.
    
    Return the results in JSON format:
    {{
        "summary_ko": "Summarized content in Korean",
        "summary_en": "Summarized content in English"
    }}
    
    ---
    {content}
    ---
    """
    
    # try:
    #     response = openai.chat.completions.create(
    #         model="gpt-3.5-turbo",
    #         messages=[{"role": "system", "content": prompt}],
    #         max_tokens=max_tokens
    #     )
    #     summary = response.choices[0].message.content
        
    #     if detected_language != "í•œêµ­ì–´":
    #         summary = f"({detected_language}ì—ì„œ ë²ˆì—­ë¨[Mediko]) {summary}"

    #     return summary
    
    # except Exception as e:
    #     print(f"âŒ ìš”ì•½ ì‹¤íŒ¨: {e}")
    #     return f"({detected_language}ì—ì„œ ë²ˆì—­ë¨[Mediko]) {content[:378]}" if detected_language != "í•œêµ­ì–´" else content[:400]  # ì‹¤íŒ¨ ì‹œ 400ì ì œí•œ
    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "system", "content": prompt}],
            max_tokens=600  # ğŸš€ ìµœëŒ€ 800 bytes ì œí•œì„ ê³ ë ¤í•˜ì—¬ ì ì ˆí•œ í† í° ì„¤ì •
        )
        result = response.choices[0].message.content.strip()

        data = json.loads(result)
        summary_ko = data.get("summary_ko", "ìš”ì•½ëœ ì‹ ê³  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
        summary_en = data.get("summary_en", "No summarized report available.")

        return summary_ko, summary_en

    except Exception as e:
        print(f"âŒ ìš”ì•½ ì‹¤íŒ¨: {e}")
        return "ìš”ì•½ëœ ì‹ ê³  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.", "No summarized report available."